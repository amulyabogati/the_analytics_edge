{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting Parole Violators"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import statsmodels.api as sm\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import metrics\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 1.1 - Loading the Dataset\r\n",
    "Load the dataset parole.csv into a data frame called parole.\r\n",
    "\r\n",
    "How many parolees are contained in the dataset?\r\n",
    "- 675"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "parole = pd.read_csv('../data/parole.csv')\r\n",
    "parole.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 675 entries, 0 to 674\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   male               675 non-null    int64  \n",
      " 1   race               675 non-null    int64  \n",
      " 2   age                675 non-null    float64\n",
      " 3   state              675 non-null    int64  \n",
      " 4   time.served        675 non-null    float64\n",
      " 5   max.sentence       675 non-null    int64  \n",
      " 6   multiple.offenses  675 non-null    int64  \n",
      " 7   crime              675 non-null    int64  \n",
      " 8   violator           675 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 47.6 KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 1.2 - Loading the Dataset\r\n",
    "How many of the parolees in the dataset violated the terms of their parole?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "parole['violator'].sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 2.1 - Preparing the Dataset\r\n",
    "You should be familiar with unordered factors. Which variables in this dataset are unordered factors with at least three levels? *Select all that apply*.\r\n",
    "- state\r\n",
    "- crime\r\n",
    "\r\n",
    "## Problem 2.2 - Preparing the Dataset\r\n",
    "In the last subproblem, we identified variables that are unordered factors with at least 3 levels, so we need to convert them to factors for our prediction problem. Convert these variables to factors (categorical). Keep in mind that we are not changing the values, just the way Python understands them (the values are still numbers).\r\n",
    "\r\n",
    "How does the output of summary() (in R) change for a factor variable as compared to a numerical variable?\r\n",
    "- The output becomes similar to that of the table() (in R) function applied to that variable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 3.1 - Splitting into a Training and Testing Set\r\n",
    "Allocate 70% to the training set and 30% to the testing set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "state_dummies = pd.get_dummies(parole['state'], prefix='state_', drop_first=True)\r\n",
    "crime_dummies = pd.get_dummies(parole['crime'], prefix='crime_', drop_first=True)\r\n",
    "dummies = pd.merge(left=state_dummies, right=crime_dummies, left_index=True, right_index=True)\r\n",
    "parole = pd.merge(left=parole, right=dummies, left_index=True, right_index=True)\r\n",
    "parole.drop(labels=['state', 'crime'], axis=1, inplace=True)\r\n",
    "\r\n",
    "features1 = list(parole.columns)\r\n",
    "features1.remove('violator')\r\n",
    "X1 = parole[features1]\r\n",
    "y1 = parole['violator']\r\n",
    "\r\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\r\n",
    "    X1, y1, train_size=0.7, random_state=144\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 4.1 - Building a Logistic Regression Model\r\n",
    "Train a logistic regression model on the training set. Your dependent variable is \"violator\", and you should use all of the other variables as independent variables.\r\n",
    "\r\n",
    "What variables are significant in this model? Significant variables should have a least one star, or should have a probability less than 0.05 (the column Pr(>|z|) in the summary output). *Select all that apply*.\r\n",
    "- race\r\n",
    "- state4\r\n",
    "- multiple.offenses"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "model1 = sm.Logit(y_train1, sm.add_constant(X_train1)).fit()\r\n",
    "print(model1.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.264284\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               violator   No. Observations:                  472\n",
      "Model:                          Logit   Df Residuals:                      459\n",
      "Method:                           MLE   Df Model:                           12\n",
      "Date:                Sat, 21 Aug 2021   Pseudo R-squ.:                  0.2658\n",
      "Time:                        10:32:30   Log-Likelihood:                -124.74\n",
      "converged:                       True   LL-Null:                       -169.89\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.312e-14\n",
      "=====================================================================================\n",
      "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                -3.6939      1.225     -3.016      0.003      -6.094      -1.293\n",
      "male                  0.4059      0.450      0.903      0.367      -0.475       1.287\n",
      "race                  0.9175      0.390      2.354      0.019       0.154       1.681\n",
      "age                   0.0098      0.016      0.609      0.543      -0.022       0.042\n",
      "time.served          -0.1034      0.119     -0.871      0.384      -0.336       0.129\n",
      "max.sentence          0.0243      0.051      0.472      0.637      -0.076       0.125\n",
      "multiple.offenses     1.4155      0.390      3.626      0.000       0.650       2.181\n",
      "state__2             -0.0061      0.483     -0.013      0.990      -0.954       0.941\n",
      "state__3              0.4478      0.550      0.815      0.415      -0.629       1.525\n",
      "state__4             -3.3082      0.622     -5.321      0.000      -4.527      -2.090\n",
      "crime__2             -0.0671      0.503     -0.133      0.894      -1.053       0.919\n",
      "crime__3             -0.3152      0.416     -0.758      0.448      -1.130       0.500\n",
      "crime__4             -0.5412      0.616     -0.878      0.380      -1.749       0.667\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 4.2 - Building a Logistic Regression Model\r\n",
    "What can we say based on the coefficient of the multiple.offenses variable?\r\n",
    "\r\n",
    "The following two properties might be useful to you when answering this question:\r\n",
    "1. If we have a coefficient c for a variable, then that means the log odds (or Logit) are increased by c for a unit increase in the variable.\r\n",
    "2. If we have a coefficient c for a variable, then that means the odds are multiplied by e^c for a unit increase in the variable.\r\n",
    "\r\n",
    "- Our model predicts that a parolee who committed multiple offenses has $e^{c}$ times higher odds of being a violator than a parolee who did not commit multiple offenses but is otherwise identical.\r\n",
    "\r\n",
    "## Problem 4.3 - Building a Logistic Regression Model\r\n",
    "Consider a parolee who is male, of white race, aged 50 years at prison release, from the state of Maryland, served 3 months, had a maximum sentence of 12 months, did not commit multiple offenses, and committed a larceny. Answer the following questions based on the model's predictions for this individual. *HINT: You should use the coefficients of your model, the Logistic Response Function, and the Odds equation to solve this problem*.\r\n",
    "\r\n",
    "According to the model, what are the odds this individual is a violator?\r\n",
    "- 0.16796494198768974\r\n",
    "\r\n",
    "According to the model, what is the probability this individual is a violator?\r\n",
    "- 0.14380991753214806"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "c = (\r\n",
    "    -4.4218     # const\r\n",
    "    + 0.4134*1  # male \r\n",
    "    + 0.8785*1  # race \r\n",
    "    + 0.0100*50 # age\r\n",
    "    + -0.1511*3 # time.served\r\n",
    "    + 0.0903*12 # max.sentence\r\n",
    "    + 1.7627*0  # multiple.offenses\r\n",
    "    + 0.2156*1  # crime2\r\n",
    ")\r\n",
    "odds = np.exp(c)\r\n",
    "prob = 1 / (1 + np.exp(-c))\r\n",
    "print(\"Odds:\", odds)\r\n",
    "print(\"Probability:\", prob)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Odds: 0.16796494198768974\n",
      "Probability: 0.14380991753214806\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 5.1 - Evaluating the Model on the Testing Set\r\n",
    "Obtain the model's predicted probabilities for parolees in the testing set.\r\n",
    "\r\n",
    "What is the maximum predicted probability of a violation?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "pred_1 = model1.predict(sm.add_constant(X_test1))\r\n",
    "pred_1.max()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7182378450775322"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 5.2 - Evaluating the Model on the Testing Set\r\n",
    "In the following questions, evaluate the model's predictions on the test set using a threshold of 0.5.\r\n",
    "\r\n",
    "What is the model's sensitivity?\r\n",
    "- 0.21739130434782608\r\n",
    "\r\n",
    "What is the model's specificity?\r\n",
    "- 0.9722222222222222\r\n",
    "\r\n",
    "What is the model's accuracy?\r\n",
    "- 0.8866995073891626"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "pred_df = y_test1.to_frame()\r\n",
    "pred_df['Predicted'] = (pred_1 >= 0.5).astype(int)\r\n",
    "\r\n",
    "cfm = pred_df.value_counts().sort_index()\r\n",
    "sensitivity = cfm.loc[1,1] / (cfm.loc[1,1] + cfm.loc[1,0])\r\n",
    "specificity = cfm.loc[0,0] / (cfm.loc[0,0] + cfm.loc[0,1])\r\n",
    "accuracy = (cfm.loc[0,0] + cfm.loc[1,1]) / cfm.sum()\r\n",
    "\r\n",
    "print(\"Sensitivity:\", sensitivity)\r\n",
    "print(\"Specificity:\", specificity)\r\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sensitivity: 0.21739130434782608\n",
      "Specificity: 0.9722222222222222\n",
      "Accuracy: 0.8866995073891626\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 5.3 - Evaluating the Model on the Testing Set\r\n",
    "What is the accuracy of a simple model that predicts that every parolee is a non-violator?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "1 - y_test1.mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8866995073891626"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 5.4 - Evaluating the Model on the Testing Set\r\n",
    "Consider a parole board using the model to predict whether parolees will be violators or not. The job of a parole board is to make sure that a prisoner is ready to be released into free society, and therefore parole boards tend to be particularily concerned about releasing prisoners who will violate their parole. Which of the following most likely describes their preferences and best course of action?\r\n",
    "- The board assigns more cost to a false negative than a false positive, and should therefore use a logistic regression cutoff less than 0.5.\r\n",
    "\r\n",
    "## Problem 5.5 - Evaluating the Model on the Testing Set\r\n",
    "Which of the following is the most accurate assessment of the value of the logistic regression model with a cutoff 0.5 to a parole board, based on the model's accuracy as compared to the simple baseline model?\r\n",
    "- The model is likely of value to the board, and using a different logistic regression cutoff is likely to improve the model's value.\r\n",
    "\r\n",
    "## Problem 5.6 - Evaluating the Model on the Testing Set\r\n",
    "What is the AUC value for the model?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "fpr, tpr, ths = metrics.roc_curve(y_test1, pred_1)\r\n",
    "auc = metrics.auc(fpr, tpr)\r\n",
    "print(auc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8632850241545893\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 5.7 - Evaluating the Model on the Testing Set\r\n",
    "Describe the meaning of AUC in this context.\r\n",
    "- The probability the model can correctly differentiate between a randomly selected parole violator and a randomly selected parole non-violator.\r\n",
    "\r\n",
    "## Problem 6.1 - Identifying Bias in Observational Data\r\n",
    "Our goal has been to predict the outcome of a parole decision, and we used a publicly available dataset of parole releases for predictions. In this final problem, we'll evaluate a potential source of bias associated with our analysis. It is always important to evaluate a dataset for possible sources of bias.\r\n",
    "\r\n",
    "The dataset contains all individuals released from parole in 2004, either due to completing their parole term or violating the terms of their parole. However, it does not contain parolees who neither violated their parole nor completed their term in 2004, causing non-violators to be underrepresented. This is called \"selection bias\" or \"selecting on the dependent variable,\" because only a subset of all relevant parolees were included in our analysis, based on our dependent variable in this analysis (parole violation). How could we improve our dataset to best address selection bias?\r\n",
    "- We should use a dataset tracking a group of parolees from the start of their parole until either they violated parole or they completed their term. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "9e6fe232ec1802e04813a62eadbd4a033db6fcefdd78d84705bbb38e45fcef4a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}