{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Demographics and Employment in the United States\r\n",
    "In the wake of the Great Recession of 2009, there has been a good deal of focus on employment statistics, one of the most important metrics policymakers use to gauge the overall strength of the economy. In the United States, the government measures unemployment using the Current Population Survey (CPS), which collects demographic and employment information from a wide range of Americans each month. In this exercise, we will employ the topics reviewed in the lectures as well as a few new techniques using the September 2013 version of this rich, nationally representative dataset.\r\n",
    "\r\n",
    "The observations in the dataset represent people surveyed in the September 2013 CPS who actually completed a survey. While the full dataset has 385 variables, in this exercise we will use a more compact version of the dataset, CPSData.csv.\r\n",
    "\r\n",
    "## Problem 1.1 - Loading and Summarizing the Dataset\r\n",
    "Load the dataset from CPSData.csv into a data frame called CPS.\r\n",
    "\r\n",
    "How many interviewees are in the dataset?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "cps = pd.read_csv('../data/CPSData.csv')\r\n",
    "cps.shape[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "131302"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 1.2 - Loading and Summarizing the Dataset\r\n",
    "Among the interviewees with a value reported for the Industry variable, what is the most common industry of employment?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "cps['Industry'].value_counts().sort_values().tail(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Educational and health services    15017\n",
       "Name: Industry, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 1.3 - Loading and Summarizing the Dataset\r\n",
    "Which state has the fewest interviewees?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "cps['State'].value_counts().sort_values().head(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "New Mexico    1102\n",
       "Name: State, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which state has the largest number of interviewees?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "cps['State'].value_counts().sort_values().tail(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "California    11570\n",
       "Name: State, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 1.4 - Loading and Summarizing the Dataset\r\n",
    "What proportion of interviewees are citizens of the United States?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "np.mean(cps['Citizenship'].str.contains('^Citizen'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9421943306271039"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 1.5 - Loading and Summarizing the Dataset\r\n",
    "The CPS differentiates between race (with possible values American Indian, Asian, Black, Pacific Islander, White, or Multiracial) and ethnicity. A number of interviewees are of Hispanic ethnicity, as captured by the Hispanic variable. For which races are there at least 250 interviewees in the CPS dataset of Hispanic ethnicity?\r\n",
    "- White\r\n",
    "- Black\r\n",
    "- Multiracial\r\n",
    "- American Indian"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "cps[cps['Hispanic']==1]['Race'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "White               16731\n",
       "Black                 621\n",
       "Multiracial           448\n",
       "American Indian       304\n",
       "Asian                 113\n",
       "Pacific Islander       77\n",
       "Name: Race, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 2.1 - Evaluating Missing Values\r\n",
    "Which variables have at least one interviewee with a missing (NA) value?\r\n",
    "- MetroAreaCode\r\n",
    "- Married\r\n",
    "- Education\r\n",
    "- EmploymentStatus\r\n",
    "- Industry"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "cps.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PeopleInHousehold         0\n",
       "Region                    0\n",
       "State                     0\n",
       "MetroAreaCode         34238\n",
       "Age                       0\n",
       "Married               25338\n",
       "Sex                       0\n",
       "Education             25338\n",
       "Race                      0\n",
       "Hispanic                  0\n",
       "CountryOfBirthCode        0\n",
       "Citizenship               0\n",
       "EmploymentStatus      25789\n",
       "Industry              65060\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 2.2 - Evaluating Missing Values\r\n",
    "Often when evaluating a new dataset, we try to identify if there is a pattern in the missing values in the dataset. We will try to determine if there is a pattern in the missing values of the Married variable.\r\n",
    "\r\n",
    "Which is the most accurate:\r\n",
    "- The Married variable being missing is related to the Age value for the interviewee."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for col in ['Region', 'Sex', 'Age', 'Citizenship']:\r\n",
    "    count_with_nulls = cps[cps['Married'].isnull()][col].value_counts().sort_index()\r\n",
    "    count_total = cps[col].value_counts().sort_index()\r\n",
    "    print(count_with_nulls / count_total)\r\n",
    "    print('*'*50)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Midwest      0.197986\n",
      "Northeast    0.173754\n",
      "South        0.191967\n",
      "West         0.204630\n",
      "Name: Region, dtype: float64\n",
      "**************************************************\n",
      "Female    0.181044\n",
      "Male      0.205591\n",
      "Name: Sex, dtype: float64\n",
      "**************************************************\n",
      "0     1.0\n",
      "1     1.0\n",
      "2     1.0\n",
      "3     1.0\n",
      "4     1.0\n",
      "     ... \n",
      "77    NaN\n",
      "78    NaN\n",
      "79    NaN\n",
      "80    NaN\n",
      "85    NaN\n",
      "Name: Age, Length: 82, dtype: float64\n",
      "**************************************************\n",
      "Citizen, Native         0.211619\n",
      "Citizen, Naturalized    0.023045\n",
      "Non-Citizen             0.064822\n",
      "Name: Citizenship, dtype: float64\n",
      "**************************************************\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 2.3 - Evaluating Missing Values\r\n",
    "How many states had all interviewees living in a non-metropolitan area (aka they have a missing MetroAreaCode value)? For this question, treat the District of Columbia as a state (even though it is not technically a state).\r\n",
    "- 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "cps.groupby('State').agg({'MetroAreaCode': lambda x: x.isnull().all()}).sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MetroAreaCode    2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many states had all interviewees living in a metropolitan area? Again, treat the District of Columbia as a state.\r\n",
    "- 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "cps.groupby('State').agg({'MetroAreaCode': lambda x: not x.isnull().any()}).sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MetroAreaCode    3\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 2.4 - Evaluating Missing Values\r\n",
    "Which region of the United States has the largest proportion of interviewees living in a non-metropolitan area?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "cps.groupby('Region').agg({'MetroAreaCode': lambda x: np.mean(x.isnull())}).sort_values(by='MetroAreaCode').tail(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         MetroAreaCode\n",
       "Region                \n",
       "Midwest       0.347869"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetroAreaCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Midwest</th>\n",
       "      <td>0.347869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 2.5 - Evaluating Missing Values\r\n",
    "Which state has a proportion of interviewees living in a non-metropolitan area closest to 30%?\r\n",
    "- Wisconsin"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "cps.groupby('State').agg({'MetroAreaCode': lambda x: np.mean(x.isnull())}).sort_values(by='MetroAreaCode')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      MetroAreaCode\n",
       "State                              \n",
       "Rhode Island               0.000000\n",
       "New Jersey                 0.000000\n",
       "District of Columbia       0.000000\n",
       "California                 0.020484\n",
       "Florida                    0.039231\n",
       "Massachusetts              0.064922\n",
       "Maryland                   0.069375\n",
       "New York                   0.080608\n",
       "Connecticut                0.085684\n",
       "Illinois                   0.112219\n",
       "Colorado                   0.129915\n",
       "Arizona                    0.131545\n",
       "Nevada                     0.133082\n",
       "Texas                      0.143705\n",
       "Louisiana                  0.161379\n",
       "Pennsylvania               0.174300\n",
       "Michigan                   0.178257\n",
       "Washington                 0.181319\n",
       "Georgia                    0.198432\n",
       "Virginia                   0.198442\n",
       "Utah                       0.210098\n",
       "Oregon                     0.218219\n",
       "Delaware                   0.233966\n",
       "New Mexico                 0.245009\n",
       "Hawaii                     0.249166\n",
       "Ohio                       0.251223\n",
       "Alabama                    0.258721\n",
       "Indiana                    0.291417\n",
       "Wisconsin                  0.299330\n",
       "South Carolina             0.313028\n",
       "Minnesota                  0.315068\n",
       "Oklahoma                   0.327643\n",
       "Missouri                   0.328671\n",
       "Tennessee                  0.355942\n",
       "Kansas                     0.362274\n",
       "North Carolina             0.373043\n",
       "Iowa                       0.486946\n",
       "Arkansas                   0.490500\n",
       "Idaho                      0.498682\n",
       "Kentucky                   0.506790\n",
       "New Hampshire              0.568745\n",
       "Nebraska                   0.581324\n",
       "Maine                      0.598321\n",
       "Vermont                    0.652381\n",
       "Mississippi                0.694309\n",
       "South Dakota               0.702500\n",
       "North Dakota               0.737386\n",
       "West Virginia              0.755855\n",
       "Montana                    0.836079\n",
       "Alaska                     1.000000\n",
       "Wyoming                    1.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetroAreaCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.020484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>0.039231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>0.064922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>0.069375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>0.080608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>0.085684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>0.112219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>0.129915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>0.131545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>0.133082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>0.143705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>0.161379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>0.174300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>0.178257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>0.181319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>0.198432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>0.198442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0.210098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.218219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>0.233966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>0.245009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>0.249166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>0.251223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>0.258721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>0.291417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>0.299330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>0.313028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>0.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>0.327643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>0.328671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>0.355942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>0.362274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>0.373043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>0.486946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>0.490500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>0.498682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>0.506790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>0.568745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>0.581324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>0.598321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>0.652381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>0.694309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>0.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>0.737386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>0.755855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>0.836079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which state has the largest proportion of non-metropolitan interviewees, ignoring states where all interviewees were non-metropolitan?\r\n",
    "- Montana\r\n",
    "\r\n",
    "## Problem 3.1 - Integrating Metropolitan Area Data\r\n",
    "Codes like MetroAreaCode and CountryOfBirthCode are a compact way to encode factor variables with text as their possible values, and they are therefore quite common in survey datasets. In fact, all but one of the variables in this dataset were actually stored by a numeric code in the original CPS datafile.\r\n",
    "\r\n",
    "When analyzing a variable stored by a numeric code, we will often want to convert it into the values the codes represent. To do this, we will use a dictionary, which maps the the code to the actual value of the variable. We have provided dictionaries MetroAreaCodes.csv and CountryCodes.csv, which respectively map MetroAreaCode and CountryOfBirthCode into their true values. Read these two dictionaries into data frames MetroAreaMap and CountryMap."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "metro_area_code = pd.read_csv('../data/MetroAreaCodes.csv')\r\n",
    "country_of_birth_code = pd.read_csv('../data/CountryCodes.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many observations (codes for metropolitan areas) are there in MetroAreaMap?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "metro_area_code.shape[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many observations (codes for countries) are there in CountryMap?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "country_of_birth_code.shape[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 3.2 - Integrating Metropolitan Area Data\r\n",
    "To merge in the metropolitan areas, we want to connect the field MetroAreaCode from the CPS data frame with the field Code in MetroAreaMap.\r\n",
    "\r\n",
    "What is the name of the variable that was added to the data frame by the merge() operation?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df = cps.merge(metro_area_code, left_on='MetroAreaCode', right_on='Code', how='left')\r\n",
    "df.columns[-1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'MetroArea'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many interviewees have a missing value for the new metropolitan area variable?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "df['MetroArea'].isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "34238"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 3.3 - Integrating Metropolitan Area Data\r\n",
    "Which of the following metropolitan areas has the largest number of interviewees?\r\n",
    "- Boston-Cambridge-Quincy, MA-NH"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df['MetroArea'].value_counts().sort_values(ascending=False).head(7)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "New York-Northern New Jersey-Long Island, NY-NJ-PA    5409\n",
       "Washington-Arlington-Alexandria, DC-VA-MD-WV          4177\n",
       "Los Angeles-Long Beach-Santa Ana, CA                  4102\n",
       "Philadelphia-Camden-Wilmington, PA-NJ-DE              2855\n",
       "Chicago-Naperville-Joliet, IN-IN-WI                   2772\n",
       "Providence-Fall River-Warwick, MA-RI                  2284\n",
       "Boston-Cambridge-Quincy, MA-NH                        2229\n",
       "Name: MetroArea, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 3.4 - Integrating Metropolitan Area Data\r\n",
    "Which metropolitan area has the highest proportion of interviewees of Hispanic ethnicity?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "df.groupby('MetroArea')['Hispanic'].mean().sort_values().tail(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MetroArea\n",
       "Laredo, TX    0.966292\n",
       "Name: Hispanic, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 3.5 - Integrating Metropolitan Area Data\r\n",
    "Determine the number of metropolitan areas in the United States from which at least 20% of interviewees are Asian.\r\n",
    "- Honolulu, HI\r\n",
    "- San Francisco-Oakland-Fremont, CA\r\n",
    "- San Jose-Sunnyvale-Santa Clara, CA\r\n",
    "- Vallejo-Fairfield, CA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "df.groupby('MetroArea').agg({'Race': lambda x: np.mean(x=='Asian')})\\\r\n",
    "    .sort_values('Race', ascending=False).head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        Race\n",
       "MetroArea                                   \n",
       "Honolulu, HI                        0.501904\n",
       "San Francisco-Oakland-Fremont, CA   0.246753\n",
       "San Jose-Sunnyvale-Santa Clara, CA  0.241791\n",
       "Vallejo-Fairfield, CA               0.203008\n",
       "Fresno, CA                          0.184818"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetroArea</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Honolulu, HI</th>\n",
       "      <td>0.501904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco-Oakland-Fremont, CA</th>\n",
       "      <td>0.246753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Jose-Sunnyvale-Santa Clara, CA</th>\n",
       "      <td>0.241791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vallejo-Fairfield, CA</th>\n",
       "      <td>0.203008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fresno, CA</th>\n",
       "      <td>0.184818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 3.6 - Integrating Metropolitan Area Data\r\n",
    "Determine which metropolitan area has the smallest proportion of interviewees who have received no high school diploma."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "df.groupby('MetroArea').agg({'Education': lambda x: np.mean(x=='No high school diploma')})\\\r\n",
    "    .sort_values('Education').head(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Education\n",
       "MetroArea               \n",
       "Iowa City, IA   0.022901"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetroArea</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iowa City, IA</th>\n",
       "      <td>0.022901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 4.1 - Integrating Country of Birth Data\r\n",
    "Just as we did with the metropolitan area information, merge in the country of birth information from the CountryMap data frame, replacing the CPS data frame with the result. If you accidentally overwrite CPS with the wrong values, remember that you can restore it by re-loading the data frame from CPSData.csv and then merging in the metropolitan area information using the command provided in the previous subproblem.\r\n",
    "\r\n",
    "What is the name of the variable added to the CPS data frame by this merge operation?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "df = df.merge(country_of_birth_code, left_on='CountryOfBirthCode', right_on='Code', how='left')\r\n",
    "df.columns[-1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Country'"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many interviewees have a missing value for the new country of birth variable?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "df['Country'].isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 4.2 - Integrating Country of Birth Data\r\n",
    "Among all interviewees born outside of North America, which country was the most common place of birth?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "df['Country'].value_counts().sort_values(ascending=False).head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "United States    115063\n",
       "Mexico             3921\n",
       "Philippines         839\n",
       "Name: Country, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 4.3 - Integrating Country of Birth Data\r\n",
    "What proportion of the interviewees from the \"New York-Northern New Jersey-Long Island, NY-NJ-PA\" metropolitan area have a country of birth that is not the United States? For this computation, don't include people from this metropolitan area who have a missing country of birth."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "np.mean(df[df['MetroArea']==\"New York-Northern New Jersey-Long Island, NY-NJ-PA\"]['Country']!='United States')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.30929931595489"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 4.4 - Integrating Country of Birth Data\r\n",
    "Which metropolitan area has the largest number (note -- not proportion) of interviewees with a country of birth in India?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "df.groupby('MetroArea').agg({'Country': lambda x: np.sum(x=='India')})\\\r\n",
    "    .sort_values(by='Country', ascending=False).head(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    Country\n",
       "MetroArea                                                  \n",
       "New York-Northern New Jersey-Long Island, NY-NJ-PA       96"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetroArea</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York-Northern New Jersey-Long Island, NY-NJ-PA</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "df.groupby('MetroArea').agg({'Country': lambda x: np.sum(x=='Brazil')})\\\r\n",
    "    .sort_values(by='Country', ascending=False).head(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                Country\n",
       "MetroArea                              \n",
       "Boston-Cambridge-Quincy, MA-NH       18"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetroArea</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Boston-Cambridge-Quincy, MA-NH</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "df.groupby('MetroArea').agg({'Country': lambda x: np.sum(x=='Somalia')})\\\r\n",
    "    .sort_values(by='Country', ascending=False).head(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        Country\n",
       "MetroArea                                      \n",
       "Minneapolis-St Paul-Bloomington, MN-WI       17"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetroArea</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Minneapolis-St Paul-Bloomington, MN-WI</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "9e6fe232ec1802e04813a62eadbd4a033db6fcefdd78d84705bbb38e45fcef4a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}